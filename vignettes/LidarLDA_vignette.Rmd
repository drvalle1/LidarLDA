---
title: "Vignette for LidarLDA"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{LidarLDA_vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Fitting the model

We start by showing how to fit the model based on simulated data with 5 clusters. The simulated datasets contain information for 2,000 pixels (rows) and 50 height bins (columns), labeled z1, z2, ..., z50. 

The data in `sim_y5` consist of the number of returned light pulses whereas the data in `sim_n5` consist of the number of incoming light pulses, in each pixel and height bin. As a result, `sim_y5` is always smaller or equal to `sim_n5`. These data were simulated with 5 clusters.

```{r setup}
#library('devtools')
#devtools::install_github("drvalle1/LidarLDA")
library(LidarLDA)

#basic characteristics of simulated data
dim(sim_y5)
dim(sim_n5)

colnames(sim_y5)
colnames(sim_n5)

mean(sim_y5<=sim_n5)
```

We fit these simulated data using the code below. In this code, we assume a maximum of 10 clusters and we rely on 10000 iterations of the gibbs sampler with a burn-in of 9000 iterations. Finally, we just return the posterior mean parameter estimates instead of all the posterior samples by specifying `theta.post=F` and `phi.post=F`.

```{r, eval=FALSE }
Model.Results=LidarLDA(y=data.matrix(sim_y5),
                       n=data.matrix(sim_n5),
                       nclust=10,
                       a.phi=1,b.phi=1,
                       gamma=0.1,ngibbs=10000,
                       nburn=9000,theta.post=F,phi.post=F)
```

We can assess convergence by examining the trace-plot of the log-likelihood. This plot suggests that the algorithm has converged.

```{r, echo=F}
#using pre-computed results stored as internal data
Model.Results=list(theta=LidarLDA:::theta,
                   llk=LidarLDA:::llk$x)
```

```{r }
plot(Model.Results$llk,type='l',xlab='Iterations',
     ylab='Log-likelihood')
```

According to the `theta` matrix (i.e., the matrix that shows the relative abundance of each cluster for each pixel), our model has identified 5 (out of a maximum of 10) main clusters. These 5 first clusters, on average, represent 99.8% of all observations in each pixel. 

```{r }
boxplot(Model.Results$theta,xlab='Cluster id',ylab='theta')

sum1=apply(Model.Results$theta[,1:5],1,sum)
mean(sum1)
```

Because this is based on simulated data, there is a nice pattern regarding how the relative abundance of each cluster changes as a function of pixel id. This is shown below.

```{r }
theta=Model.Results$theta
npix=nrow(theta)
plot(NA,NA,xlim=c(0,npix),ylim=c(0,1),ylab='theta',xlab='pixel id')
for (i in 1:5) lines(1:npix,theta[,i],col=i)
```

## Generating simulated data

Here we provide the code showing how the simulated data sets `sim_y5` and `sim_n5` were generated. This code can be useful for users interested in modifying the simulated data sets to see how the model behaves for different settings.

```{r }
rm(list=ls(all=TRUE))
set.seed(421)

npix=2000
nheight=50
nclust=5
base=floor(npix/(nclust-2))

#generate thetas
x=seq(from=-1,to=1,length.out=base)
y=sqrt(1-(x^2))*0.1
min1=0.0001
y[y<min1]=min1
# plot(x,y)

init=floor(npix/nclust)
seq1=c(seq(from=1,to=npix,by=init),npix)

theta=matrix(min1,npix,nclust)
for (i in 1:nclust){
  seq2=seq1[i]:(seq1[i]+base-1)
  seq3=seq2[seq2<=npix]
  theta[seq3,i]=y[1:length(seq3)]
}
theta=theta/matrix(apply(theta,1,sum),npix,nclust)
theta.true=theta

plot(NA,NA,xlim=c(0,npix),ylim=c(0,1),xlab='pixel id',ylab='theta')
for (i in 1:nclust) lines(1:npix,theta[,i],col=i)

#generate phi
tmp=matrix(rbeta(nclust*nheight,0.5,0.5),nclust,nheight)
tmp[,1:nclust]=diag(0.8,nclust)
phi=tmp
phi.true=phi

#get n
n2=matrix(round(runif(npix*nheight,min=10,max=200)),npix,nheight)

#generate actual observations y
y=matrix(0,npix,nheight)
array1=array(NA,dim=c(npix,nheight,nclust,2))
for (i in 1:npix){
  for (j in 1:nheight){
    tmp=rmultinom(1,size=n2[i,j],prob=theta[i,])
    for (k in 1:nclust){
      tmp1=rbinom(1,size=tmp[k],prob=phi[k,j])
      array1[i,j,k,1]=tmp1
      array1[i,j,k,2]=tmp[k]-tmp1
      y[i,j]=y[i,j]+tmp1
    }
  }
}
mean(y<=n2)
# image(data.matrix(y/n2))

#add column names
colnames(y)=colnames(n2)=paste('z',1:nheight,sep='')
sim_y5=y
sim_n5=n2
```

## Editing empirical LIDAR data

To use this model to fit empirical LIDAR data, it is important to format the data correctly. Here we show how we have formatted an empirical LIDAR data set. 

We start by assuming that we have a matrix called `lidar_data` which holds the number of returns in each pixel and each height bin. Notice that this matrix also contains the x and y coordinates of each pixel.  

```{r }
library(LidarLDA)

dim(lidar_data)
colnames(lidar_data)
```

Next, we remove height bins for which there is not much data because these are relatively uninformative. In our case, there are almost no returns in bins above 31.5 m, as shown below. As a result, we sum all of the returns above this threshold and assign these results to the last height bin (i.e., `z31.5`).

```{r }
dat=lidar_data

#get rid of height bins with few data
apply(dat,2,sum)
limite='z31.5'
ind=which(colnames(dat)==limite)
dat1=dat

#all of the returns above this threshold get stored in the highest bin
dat1[,ind]=apply(dat1[,ind:ncol(dat)],1,sum)
dat2=dat1[,1:ind]
ind=grep('z',colnames(dat2))
coord=dat2[,-ind]
dat3=dat2[,ind]
```

Finally, I create the matrices `y` and `n`, containing the number of returned light pulses and incoming light pulses, respectively, for each pixel and each height bin.

```{r }
y=z=dat3
nheight=ncol(z)
npix=nrow(z)

#get n matrix
n=matrix(NA,npix,nheight)
for (i in nheight:2){
  n[,i]=rowSums(z)
  z=z[,-i]
}
n[,1]=y[,1]

#get names
colnames(n)=colnames(y)

#eliminate the first column because y/n is always equal to 1 for that column
n1=n[,-1]
y1=y[,-1]
```

Finally, to reduce the number of light pulses, ensure an approximately even number of pulses in each height bin in each pixel (here arbitrarily set to 100), and ensure more rapid convergence, we finish formating these data using the following code.

```{r }
set.seed(1)
prob=y1/n1
cond=n1>100
n1[cond]=100
y1[cond]=rbinom(sum(cond),size=100,prob[cond])
```

## Fitting empirical LIDAR data and displaying results

We can now fit LidarLDA to the `y1` and `n1` matrices.

```{r, eval=F}
Model.Results=LidarLDA(y=data.matrix(y1),
                       n=data.matrix(n1),
                       nclust=10,
                       a.phi=1,b.phi=1,
                       gamma=0.1,ngibbs=10000,
                       nburn=9000,theta.post=F,phi.post=F)
```

```{r ,echo=F }
#using pre-computed results stored as internal data
Model.Results=list(theta=LidarLDA:::theta_empirical,
                   llk=LidarLDA:::llk$x,
                   phi=LidarLDA:::phi_empirical)
```

Our results suggest that 3 main clusters exist in this data set. 

```{r }
boxplot(Model.Results$theta,ylab='theta',xlab='Cluster id')
```

The estimated absorptance probabilities for each cluster suggest that cluster 2 includes a combination of short and high vegetation while cluster 1 is comprised mostly of short vegetation. Finally, cluster 3 is a vegetation type with intermediate height.

```{r }
par(mfrow=c(3,1),mar=rep(1,4),oma=c(4,4,1,1))
phi=data.matrix(Model.Results$phi)
plot(phi[1,],type='h')
plot(phi[2,],type='h')
plot(phi[3,],type='h')
mtext(side=1,at=0.5,outer=T,line=1,'Height (m)')
mtext(side=2,at=0.5,outer=T,line=1,'Absorptance probability')
```

The spatial distribution of clusters 1 and 2 are shown below.

```{r }
library('ggplot2')
theta=Model.Results$theta
colnames(theta)=paste0('cluster',1:10)
results=cbind(coord,theta)

ggplot() +
  geom_tile(data = results, alpha = 0.8,aes(x = xcoord, y = ycoord,fill = cluster1)) +
  scale_fill_gradient2(low = "cyan", mid = "red",high='purple',limits=c(0,1),midpoint=0.5)

ggplot() +
  geom_tile(data = results, alpha = 0.8,aes(x = xcoord, y = ycoord,fill = cluster2)) +
  scale_fill_gradient2(low = "cyan", mid = "red",high='purple',limits=c(0,1),midpoint=0.5)
```
